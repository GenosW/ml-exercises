{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n0   0   8   6  10   6   7   2   2   2   3  ...      1      0      0      0   \n1   1  13   1  13   9   8   8   2   3   2  ...      4      1      2      1   \n2   2  16   7   6   7   9   3   4   2   6  ...      0      0      0      0   \n3   3   8  11  10  11   3   7   0   4   2  ...      0      0      1      0   \n4   4  10  11   8   5   3   4   2   5   5  ...      0      0      0      0   \n\n   V9996  V9997  V9998  V9999  V10000     Class  \n0      0      0      0      0       0     Chell  \n1      0      1      0      0       0  Engineer  \n2      1      0      0      0       0     Grove  \n3      0      0      2      1       0  Davisson  \n4      0      0      0      0       0    Wilson  \n\n[5 rows x 10002 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chell</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>13</td>\n      <td>9</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>16</td>\n      <td>7</td>\n      <td>6</td>\n      <td>7</td>\n      <td>9</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Grove</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8</td>\n      <td>11</td>\n      <td>10</td>\n      <td>11</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Davisson</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>10</td>\n      <td>11</td>\n      <td>8</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Wilson</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 10002 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/amazon/amazon_review_ID.shuf.lrn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_features = StandardScaler().fit_transform(df.loc[:,'V1':'V10000'].values)\n",
    "#X_train = pd.DataFrame(scaled_features, index=df.loc[:,'V1':'V10000'].index, columns=df.loc[:,'V1':'V10000'].columns)\n",
    "X_lrn = df.loc[:,'V1':'V10000']\n",
    "scaled_features = StandardScaler().fit_transform(X_lrn.values)\n",
    "X_lrn = pd.DataFrame(scaled_features, index=X_lrn.index, columns=X_lrn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Class\n0       Chell\n1    Engineer\n2       Grove\n3    Davisson\n4      Wilson\n..        ...\n745     Riley\n746      Neal\n747   Messick\n748  Mitchell\n749    Comdet\n\n[750 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chell</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Grove</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Davisson</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wilson</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>Riley</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>Neal</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>Messick</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>Mitchell</td>\n    </tr>\n    <tr>\n      <th>749</th>\n      <td>Comdet</td>\n    </tr>\n  </tbody>\n</table>\n<p>750 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "Y_lrn = df.loc[:,'Class':'Class']\n",
    "Y_lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9991  V9992  V9993  V9994  \\\n0  15  10   6   7   9   3   3   3   1    1  ...      0      0      1      1   \n1   8  10   7   2   5   7   2   5   3    3  ...      0      4      0      0   \n2  18   9   7   8   8   7  12   6   7    1  ...      0      0      1      0   \n3   6   5   4   2   4   1   1   1   0    3  ...      0      2      0      0   \n4   9   3   2   5   9   3   0   3   2    4  ...      0      0      0      0   \n\n   V9995  V9996  V9997  V9998  V9999  V10000  \n0      0      0      0      0      0       0  \n1      0      0      0      2      1       0  \n2      0      0      1      0      0       1  \n3      0      0      0      1      0       0  \n4      0      0      0      1      0       0  \n\n[5 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>10</td>\n      <td>6</td>\n      <td>7</td>\n      <td>9</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>10</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18</td>\n      <td>9</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>12</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>9</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_test = pd.read_csv('Datasets/amazon/amazon_review_ID.shuf.tes.csv').drop('ID', axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier for Amazon Review Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_lrn, Y_lrn, test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "########################################\nmax_features: 0.1\noob score: 0.5422222222222223\nnumber of validation samples: 300\naccuracy: 55.00% --> 165\n########################################\nmax_features: 0.2\noob score: 0.5222222222222223\nnumber of validation samples: 300\naccuracy: 53.33% --> 160\n########################################\nmax_features: 0.30000000000000004\noob score: 0.5333333333333333\nnumber of validation samples: 300\naccuracy: 53.00% --> 159\n########################################\nmax_features: 0.4\noob score: 0.5511111111111111\nnumber of validation samples: 300\naccuracy: 52.33% --> 157\n########################################\nmax_features: 0.5\noob score: 0.5511111111111111\nnumber of validation samples: 300\naccuracy: 51.33% --> 154\n########################################\nmax_features: 0.6\noob score: 0.5222222222222223\nnumber of validation samples: 300\naccuracy: 50.00% --> 150\n########################################\nmax_features: 0.7000000000000001\noob score: 0.5511111111111111\nnumber of validation samples: 300\naccuracy: 52.33% --> 157\n########################################\nmax_features: 0.8\noob score: 0.5333333333333333\nnumber of validation samples: 300\naccuracy: 50.33% --> 151\n########################################\nmax_features: 0.9\noob score: 0.5355555555555556\nnumber of validation samples: 300\naccuracy: 50.67% --> 152\n########################################\nmax_features: 1.0\noob score: 0.5377777777777778\nnumber of validation samples: 300\naccuracy: 49.67% --> 149\n----------------------------------------\n"
    }
   ],
   "source": [
    "num_threads = 3\n",
    "scores = []\n",
    "\n",
    "for feats in np.linspace(0.1,1,10):\n",
    "    print(\"#\"*40)\n",
    "    print(\"max_features:\", feats)\n",
    "    rf = RFC(n_jobs=num_threads,n_estimators=400, max_features=feats, bootstrap=True, oob_score=True)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    print(\"oob score:\", rf.oob_score_)\n",
    "    rf.get_params()\n",
    "    Y_pred = rf.predict(X_valid)\n",
    "    score = accuracy_score(Y_valid, Y_pred)\n",
    "    print(f\"number of validation samples: {X_valid.shape[0]}\")\n",
    "    print(f\"accuracy: {score*100:.2f}% --> {accuracy_score(Y_valid, Y_pred, normalize=False)}\")\n",
    "    scores.append(score)\n",
    "else:\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "oob score: 0.5444444444444444\nnumber of validation samples: 300\naccuracy: 55.67% --> 167\n"
    }
   ],
   "source": [
    "rf = RFC(n_jobs=num_threads, n_estimators=800, max_features=\"auto\", min_samples_split=2, min_samples_leaf=1, max_depth=40, bootstrap=True, oob_score=True)\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"oob score:\", rf.oob_score_)\n",
    "rf.get_params()\n",
    "Y_pred = rf.predict(X_valid)\n",
    "score = accuracy_score(Y_valid, Y_pred)\n",
    "print(f\"number of validation samples: {X_valid.shape[0]}\")\n",
    "print(f\"accuracy: {score*100:.2f}% --> {accuracy_score(Y_valid, Y_pred, normalize=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary first try\n",
    "\n",
    "* A (pretty much) default RandomForestClassifier reaches an accuracy of ~42%...not that great.\n",
    "Let's see if we can tweak it a bit...\n",
    "\n",
    "* Tweaking hyper parameters by hand for a bit, we can get a score ~56% on the validation set\n",
    "\n",
    "* With RandomizedSearchCV, we can get a OOB score of 60%...lets check on the validation set: 57%...hm, not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators=[100, 400, 600, 800, 1000]\n",
    "max_features=[\"auto\", \"sqrt\", \"log2\"]\n",
    "max_depth=[5,15,20,30,40]\n",
    "min_samples_leaf=[1,2,5,10]\n",
    "min_samples_split=[2,4,8,12]\n",
    "\n",
    "params_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"min_samples_split\": min_samples_split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   24.1s\n[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.1min finished\nBest params: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 30}\nBest score: 0.5955555555555555\n"
    }
   ],
   "source": [
    "RFC_GS = RandomizedSearchCV(estimator=RFC(random_state=42),\n",
    "                    param_distributions=params_grid,\n",
    "                    n_iter=20,\n",
    "                    n_jobs=4,\n",
    "                    cv=5,\n",
    "                    verbose=2,\n",
    "                    random_state=40\n",
    ")\n",
    "RFC_GS.fit(X_train, Y_train)\n",
    "print(\"Best params:\", RFC_GS.best_params_)\n",
    "print(\"Best score:\", RFC_GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of validation samples: 300\naccuracy: 57.67% --> 173\n"
    }
   ],
   "source": [
    "Y_pred = RFC_GS.predict(X_valid)\n",
    "score = accuracy_score(Y_valid, Y_pred)\n",
    "print(f\"number of validation samples: {X_valid.shape[0]}\")\n",
    "print(f\"accuracy: {score*100:.2f}% --> {accuracy_score(Y_valid, Y_pred, normalize=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "Let's try to reduce the dimensionality, maybe we can get a better model that way --> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_lrn, Y_lrn, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of instances: 525\nNumber of features: 10000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n264  0.208221 -0.122133 -0.518430  1.162266 -0.969191 -0.935059  1.823759   \n565  0.383295  2.470308  0.075646  0.386963  1.500086  1.189003  1.321991   \n441  1.083591  1.318112  0.669722  0.903832 -0.351872  1.189003 -0.685080   \n477 -1.017296 -0.410182 -1.112506  0.128528 -1.586510  1.189003 -0.434196   \n195  0.733443 -0.410182 -0.221392 -0.646775 -1.277851 -0.227039  0.569339   \n..        ...       ...       ...       ...       ...       ...       ...   \n557 -1.892666  0.742014  0.075646 -0.646775 -1.277851 -0.935059  1.823759   \n193  0.383295  2.182259 -0.221392 -1.422079  0.265447 -0.935059  0.820223   \n617  0.733443 -0.986280  0.966760 -0.646775 -0.351872  0.126972  0.569339   \n343  0.558369 -0.122133  0.075646 -0.388341  1.191426  0.480982 -0.685080   \n351  0.558369  1.318112  2.154912  0.903832 -0.043212  0.480982 -0.935964   \n\n           V8        V9       V10  ...     V9991     V9992     V9993  \\\n264  0.166034 -0.446508 -0.681628  ... -0.384867 -0.358025 -0.397250   \n565 -0.264849  1.925170  1.442559  ... -0.384867 -0.358025 -0.397250   \n441 -0.264849 -0.920843 -0.327597  ... -0.384867 -0.358025 -0.397250   \n477 -1.557498  0.502163 -0.327597  ... -0.384867 -0.358025 -0.397250   \n195 -1.126615  0.027828  0.026434  ...  1.442034 -0.358025 -0.397250   \n..        ...       ...       ...  ...       ...       ...       ...   \n557 -1.557498 -0.920843 -0.327597  ... -0.384867 -0.358025 -0.397250   \n193 -0.695732  0.976499 -1.035659  ... -0.384867 -0.358025  1.537411   \n617 -1.126615 -0.446508  2.150621  ... -0.384867 -0.358025  1.537411   \n343  0.596917  0.027828  1.442559  ... -0.384867 -0.358025 -0.397250   \n351  1.027800  0.027828  0.026434  ... -0.384867 -0.358025 -0.397250   \n\n        V9994     V9995     V9996     V9997     V9998     V9999    V10000  \n264 -0.323400 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n565 -0.323400 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n441 -0.323400 -0.394041 -0.450704 -0.430273  1.748000 -0.462312 -0.375244  \n477 -0.323400 -0.394041 -0.450704 -0.430273 -0.390662  1.553584 -0.375244  \n195 -0.323400 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n..        ...       ...       ...       ...       ...       ...       ...  \n557 -0.323400 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n193  3.045354 -0.394041  3.646602  1.561732 -0.390662  1.553584 -0.375244  \n617  1.360977 -0.394041 -0.450704 -0.430273  1.748000 -0.462312 -0.375244  \n343 -0.323400  1.365069  1.597949 -0.430273 -0.390662 -0.462312 -0.375244  \n351 -0.323400 -0.394041 -0.450704  5.545743 -0.390662 -0.462312 -0.375244  \n\n[525 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>264</th>\n      <td>0.208221</td>\n      <td>-0.122133</td>\n      <td>-0.518430</td>\n      <td>1.162266</td>\n      <td>-0.969191</td>\n      <td>-0.935059</td>\n      <td>1.823759</td>\n      <td>0.166034</td>\n      <td>-0.446508</td>\n      <td>-0.681628</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>0.383295</td>\n      <td>2.470308</td>\n      <td>0.075646</td>\n      <td>0.386963</td>\n      <td>1.500086</td>\n      <td>1.189003</td>\n      <td>1.321991</td>\n      <td>-0.264849</td>\n      <td>1.925170</td>\n      <td>1.442559</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>1.083591</td>\n      <td>1.318112</td>\n      <td>0.669722</td>\n      <td>0.903832</td>\n      <td>-0.351872</td>\n      <td>1.189003</td>\n      <td>-0.685080</td>\n      <td>-0.264849</td>\n      <td>-0.920843</td>\n      <td>-0.327597</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>1.748000</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>-1.017296</td>\n      <td>-0.410182</td>\n      <td>-1.112506</td>\n      <td>0.128528</td>\n      <td>-1.586510</td>\n      <td>1.189003</td>\n      <td>-0.434196</td>\n      <td>-1.557498</td>\n      <td>0.502163</td>\n      <td>-0.327597</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>1.553584</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>0.733443</td>\n      <td>-0.410182</td>\n      <td>-0.221392</td>\n      <td>-0.646775</td>\n      <td>-1.277851</td>\n      <td>-0.227039</td>\n      <td>0.569339</td>\n      <td>-1.126615</td>\n      <td>0.027828</td>\n      <td>0.026434</td>\n      <td>...</td>\n      <td>1.442034</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>-1.892666</td>\n      <td>0.742014</td>\n      <td>0.075646</td>\n      <td>-0.646775</td>\n      <td>-1.277851</td>\n      <td>-0.935059</td>\n      <td>1.823759</td>\n      <td>-1.557498</td>\n      <td>-0.920843</td>\n      <td>-0.327597</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>0.383295</td>\n      <td>2.182259</td>\n      <td>-0.221392</td>\n      <td>-1.422079</td>\n      <td>0.265447</td>\n      <td>-0.935059</td>\n      <td>0.820223</td>\n      <td>-0.695732</td>\n      <td>0.976499</td>\n      <td>-1.035659</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>1.537411</td>\n      <td>3.045354</td>\n      <td>-0.394041</td>\n      <td>3.646602</td>\n      <td>1.561732</td>\n      <td>-0.390662</td>\n      <td>1.553584</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>617</th>\n      <td>0.733443</td>\n      <td>-0.986280</td>\n      <td>0.966760</td>\n      <td>-0.646775</td>\n      <td>-0.351872</td>\n      <td>0.126972</td>\n      <td>0.569339</td>\n      <td>-1.126615</td>\n      <td>-0.446508</td>\n      <td>2.150621</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>1.537411</td>\n      <td>1.360977</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>1.748000</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>0.558369</td>\n      <td>-0.122133</td>\n      <td>0.075646</td>\n      <td>-0.388341</td>\n      <td>1.191426</td>\n      <td>0.480982</td>\n      <td>-0.685080</td>\n      <td>0.596917</td>\n      <td>0.027828</td>\n      <td>1.442559</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>1.365069</td>\n      <td>1.597949</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>0.558369</td>\n      <td>1.318112</td>\n      <td>2.154912</td>\n      <td>0.903832</td>\n      <td>-0.043212</td>\n      <td>0.480982</td>\n      <td>-0.935964</td>\n      <td>1.027800</td>\n      <td>0.027828</td>\n      <td>0.026434</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.323400</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>5.545743</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n  </tbody>\n</table>\n<p>525 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(\"Number of instances:\", X_train.shape[0])\n",
    "num_feats= X_train.shape[1]\n",
    "print(\"Number of features:\", num_feats)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  3.43031832 -11.02916433 -10.93644191 ...   8.60619006  -1.60762178\n   -5.08292838]\n [-17.70724146   4.98351004   5.31304765 ...   6.27694436 -19.39977635\n  -32.36025976]\n [ -9.90189988 -12.24126874   4.47293615 ...  -5.02400454   0.85935305\n    7.20458717]\n ...\n [ -0.21937413  16.45736067   6.95456505 ...   4.33777165 -13.67547033\n    3.37992258]\n [ -6.68354154  12.77948213   9.18344174 ...  -6.25308349  -5.59248949\n   12.92406473]\n [-14.57262466 -15.52561783   8.50130432 ...  -3.46292295   1.51275031\n   -4.97226477]]\n[[  3.43008764 -11.02642128 -10.9610951  ...   1.52688707  -3.75835742\n    4.559674  ]\n [-17.70758452   4.98147928   5.70882445 ...  -3.82346076 -10.00935104\n   -6.40030536]\n [ -9.90198953 -12.24352585   4.57060409 ...  -4.81813595   5.4501248\n    5.45628198]\n ...\n [ -0.21929722  16.45566635   6.98786628 ...   2.61760081   3.10750442\n    0.72737129]\n [ -6.68294033  12.78351638   9.19057933 ...  10.74951608  -4.47877612\n    3.16743832]\n [-14.57248686 -15.52820414   8.41477427 ...  -8.4766835    2.9316155\n   -1.71811068]]\n[[  3.42890479 -11.02838674 -10.88953467 ...   6.16580571  -7.70561683\n    1.1418974 ]\n [-17.70509723   4.99109724   5.65388579 ...   5.14021316  -0.33022505\n    0.5284753 ]\n [ -9.9053968  -12.24562173   4.55136337 ...  -1.7523605   -2.8237384\n   11.87507992]\n ...\n [ -0.21804893  16.44940096   6.96085333 ...  -0.51195391   5.61033576\n   -1.25957608]\n [ -6.68411052  12.77331626   9.2927101  ...   2.77348764  -1.13009109\n   11.34092418]\n [-14.57438655 -15.53987099   8.50571411 ...   0.16831464  -0.19070434\n   -4.58687409]]\n[[  3.43020331 -11.02812767 -10.89304286 ...   3.98301468  -0.63421405\n    1.21410374]\n [-17.70743705   4.98098335   5.67037318 ...  -1.47676153  -5.24387552\n   -5.0064116 ]\n [ -9.90203851 -12.24459281   4.54324794 ... -10.19350572  -4.11411441\n   -0.63355016]\n ...\n [ -0.21957123  16.45709957   6.9911065  ...  -3.71237238  -4.15644659\n    3.74449914]\n [ -6.68351138  12.78510263   9.14289743 ...   0.99834954  -1.91719489\n   -8.69401613]\n [-14.57304242 -15.52923762   8.50054304 ...  -4.65764142   0.55096087\n    7.08582939]]\n[[  3.43021952 -11.02480862 -10.89916771 ...   1.80079891  -4.63352421\n    5.5536996 ]\n [-17.70762699   4.9827796    5.6611893  ...   1.26415947   1.22020159\n    3.58008047]\n [ -9.90226171 -12.24319286   4.53762851 ...  -2.77058158  -4.34601123\n    3.40460956]\n ...\n [ -0.21924359  16.45721242   6.99051876 ...  -8.38278236  -0.45255984\n    5.75085606]\n [ -6.68302663  12.78328106   9.12700029 ...   1.12941094   6.79367299\n    1.20422218]\n [-14.57200613 -15.52911806   8.48385288 ...   8.61455299  -2.65905937\n   -5.04822187]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcas = [PCA(n_components=n) for n in [10, 25, 100, 200, 225]]\n",
    "pcas_objs = [pca.fit(X_train.values) for pca in pcas]\n",
    "pcas = [pca.transform(X_train.values) for pca in pcas_objs]\n",
    "#PCA(copy=True, iterated_power='auto', n_components=2, random_state=None, svd_solver='auto', tol=0.0, whiten=False)\n",
    "for pca in pcas:\n",
    "    print(pca)\n",
    "#pcas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDfs = [pd.DataFrame(data=pca, columns=[f\"pc{i}\" for i in range(1,1+pca.shape[1])]) for pca in pcas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "RF_PCAs = [RFC(n_jobs=-1, n_estimators=500, max_features=\"auto\", bootstrap=True, oob_score=True) for _ in pcas]\n",
    "RF_PCAs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            pc1        pc2        pc3        pc4        pc5        pc6  \\\n0     16.511131 -26.715407   7.838281  12.940739   6.049301  -4.361738   \n1      5.438262  -9.955346  -8.356810   8.141005  -6.591115 -10.695282   \n2     28.339026  28.685332 -15.662330  -4.678663  -8.287392  -5.583929   \n3     44.665211  17.579839 -18.115547   6.361071   1.131066  -6.218566   \n4    -82.941278 -10.768527 -17.960391   8.959819  -4.222943   7.725968   \n..          ...        ...        ...        ...        ...        ...   \n445   50.868923  26.250521   9.118975   2.606305 -20.653768  -8.584164   \n446  250.563147  -3.637493   9.094398   5.098351   0.577620   6.763806   \n447  -79.290698  41.484774 -29.935563   2.878177  -8.339005  10.182994   \n448   43.463790   0.770065 -10.147937   3.858490 -17.105523 -10.306441   \n449   49.922700   7.560325   0.877575  15.640722 -24.899733   9.896629   \n\n           pc7        pc8        pc9       pc10  ...      pc91      pc92  \\\n0    -5.769944  -9.433231   4.295321  -9.539890  ... -5.787394 -1.986740   \n1    16.302858  -0.145316   0.326995   7.353725  ...  1.837024  2.903904   \n2   -12.435026  -0.034747  -7.322805 -12.031544  ...  3.718606 -6.603676   \n3   -25.498921  17.828425   6.611678   2.780941  ...  3.636660  1.073634   \n4    -1.075946  10.384305  20.615799  -4.527702  ...  3.155064 -3.662313   \n..         ...        ...        ...        ...  ...       ...       ...   \n445 -10.588731 -17.103068 -12.675352 -11.609654  ... -1.712956 -2.124834   \n446  -4.092140   0.434605  -0.778162  -5.914144  ... -1.482152  0.132980   \n447  11.381218 -24.395054  -5.752277  11.752378  ... -5.954199  2.607926   \n448  11.203982  24.482049   2.786993   1.824428  ...  1.069280  1.637443   \n449 -18.725087  -8.175912   5.921101   1.245585  ... -3.041447 -5.247709   \n\n         pc93      pc94      pc95      pc96      pc97      pc98       pc99  \\\n0   -4.590370 -1.825168  3.783025  2.885989  0.063593  6.822076  -4.211299   \n1    0.126196 -4.095129  4.314417  3.622759  0.664839 -1.429220  -3.553942   \n2   -3.891210  0.088692  2.024708  1.182754 -4.758555  6.244366   3.613868   \n3    2.030238 -2.590020 -3.552134  1.859899 -2.272525 -0.664115  -3.020105   \n4    0.789542  3.876188  4.620672 -2.447962 -4.634747  1.933976 -10.253075   \n..        ...       ...       ...       ...       ...       ...        ...   \n445  3.838165  0.305233  1.103200 -0.823556 -0.809239  0.421367   8.138387   \n446 -0.554026  1.829123  0.905477  1.737027  0.025944  2.211530   0.445932   \n447 -4.492053  0.982648 -7.818147 -1.135596 -2.743912  1.518003  -2.633035   \n448 -0.467356 -2.863164 -1.713703 -3.485192 -7.518907 -1.735287  -0.889591   \n449  2.939720  3.391208 -0.883789 -1.504317 -2.896758  6.306368  -0.465965   \n\n        pc100  \n0   -2.367464  \n1   -0.147547  \n2   -3.222606  \n3    6.059327  \n4   -5.320339  \n..        ...  \n445 -2.764782  \n446  0.628753  \n447 -5.682491  \n448  7.868883  \n449 -3.895691  \n\n[450 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pc1</th>\n      <th>pc2</th>\n      <th>pc3</th>\n      <th>pc4</th>\n      <th>pc5</th>\n      <th>pc6</th>\n      <th>pc7</th>\n      <th>pc8</th>\n      <th>pc9</th>\n      <th>pc10</th>\n      <th>...</th>\n      <th>pc91</th>\n      <th>pc92</th>\n      <th>pc93</th>\n      <th>pc94</th>\n      <th>pc95</th>\n      <th>pc96</th>\n      <th>pc97</th>\n      <th>pc98</th>\n      <th>pc99</th>\n      <th>pc100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.511131</td>\n      <td>-26.715407</td>\n      <td>7.838281</td>\n      <td>12.940739</td>\n      <td>6.049301</td>\n      <td>-4.361738</td>\n      <td>-5.769944</td>\n      <td>-9.433231</td>\n      <td>4.295321</td>\n      <td>-9.539890</td>\n      <td>...</td>\n      <td>-5.787394</td>\n      <td>-1.986740</td>\n      <td>-4.590370</td>\n      <td>-1.825168</td>\n      <td>3.783025</td>\n      <td>2.885989</td>\n      <td>0.063593</td>\n      <td>6.822076</td>\n      <td>-4.211299</td>\n      <td>-2.367464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.438262</td>\n      <td>-9.955346</td>\n      <td>-8.356810</td>\n      <td>8.141005</td>\n      <td>-6.591115</td>\n      <td>-10.695282</td>\n      <td>16.302858</td>\n      <td>-0.145316</td>\n      <td>0.326995</td>\n      <td>7.353725</td>\n      <td>...</td>\n      <td>1.837024</td>\n      <td>2.903904</td>\n      <td>0.126196</td>\n      <td>-4.095129</td>\n      <td>4.314417</td>\n      <td>3.622759</td>\n      <td>0.664839</td>\n      <td>-1.429220</td>\n      <td>-3.553942</td>\n      <td>-0.147547</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.339026</td>\n      <td>28.685332</td>\n      <td>-15.662330</td>\n      <td>-4.678663</td>\n      <td>-8.287392</td>\n      <td>-5.583929</td>\n      <td>-12.435026</td>\n      <td>-0.034747</td>\n      <td>-7.322805</td>\n      <td>-12.031544</td>\n      <td>...</td>\n      <td>3.718606</td>\n      <td>-6.603676</td>\n      <td>-3.891210</td>\n      <td>0.088692</td>\n      <td>2.024708</td>\n      <td>1.182754</td>\n      <td>-4.758555</td>\n      <td>6.244366</td>\n      <td>3.613868</td>\n      <td>-3.222606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44.665211</td>\n      <td>17.579839</td>\n      <td>-18.115547</td>\n      <td>6.361071</td>\n      <td>1.131066</td>\n      <td>-6.218566</td>\n      <td>-25.498921</td>\n      <td>17.828425</td>\n      <td>6.611678</td>\n      <td>2.780941</td>\n      <td>...</td>\n      <td>3.636660</td>\n      <td>1.073634</td>\n      <td>2.030238</td>\n      <td>-2.590020</td>\n      <td>-3.552134</td>\n      <td>1.859899</td>\n      <td>-2.272525</td>\n      <td>-0.664115</td>\n      <td>-3.020105</td>\n      <td>6.059327</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-82.941278</td>\n      <td>-10.768527</td>\n      <td>-17.960391</td>\n      <td>8.959819</td>\n      <td>-4.222943</td>\n      <td>7.725968</td>\n      <td>-1.075946</td>\n      <td>10.384305</td>\n      <td>20.615799</td>\n      <td>-4.527702</td>\n      <td>...</td>\n      <td>3.155064</td>\n      <td>-3.662313</td>\n      <td>0.789542</td>\n      <td>3.876188</td>\n      <td>4.620672</td>\n      <td>-2.447962</td>\n      <td>-4.634747</td>\n      <td>1.933976</td>\n      <td>-10.253075</td>\n      <td>-5.320339</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>50.868923</td>\n      <td>26.250521</td>\n      <td>9.118975</td>\n      <td>2.606305</td>\n      <td>-20.653768</td>\n      <td>-8.584164</td>\n      <td>-10.588731</td>\n      <td>-17.103068</td>\n      <td>-12.675352</td>\n      <td>-11.609654</td>\n      <td>...</td>\n      <td>-1.712956</td>\n      <td>-2.124834</td>\n      <td>3.838165</td>\n      <td>0.305233</td>\n      <td>1.103200</td>\n      <td>-0.823556</td>\n      <td>-0.809239</td>\n      <td>0.421367</td>\n      <td>8.138387</td>\n      <td>-2.764782</td>\n    </tr>\n    <tr>\n      <th>446</th>\n      <td>250.563147</td>\n      <td>-3.637493</td>\n      <td>9.094398</td>\n      <td>5.098351</td>\n      <td>0.577620</td>\n      <td>6.763806</td>\n      <td>-4.092140</td>\n      <td>0.434605</td>\n      <td>-0.778162</td>\n      <td>-5.914144</td>\n      <td>...</td>\n      <td>-1.482152</td>\n      <td>0.132980</td>\n      <td>-0.554026</td>\n      <td>1.829123</td>\n      <td>0.905477</td>\n      <td>1.737027</td>\n      <td>0.025944</td>\n      <td>2.211530</td>\n      <td>0.445932</td>\n      <td>0.628753</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>-79.290698</td>\n      <td>41.484774</td>\n      <td>-29.935563</td>\n      <td>2.878177</td>\n      <td>-8.339005</td>\n      <td>10.182994</td>\n      <td>11.381218</td>\n      <td>-24.395054</td>\n      <td>-5.752277</td>\n      <td>11.752378</td>\n      <td>...</td>\n      <td>-5.954199</td>\n      <td>2.607926</td>\n      <td>-4.492053</td>\n      <td>0.982648</td>\n      <td>-7.818147</td>\n      <td>-1.135596</td>\n      <td>-2.743912</td>\n      <td>1.518003</td>\n      <td>-2.633035</td>\n      <td>-5.682491</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>43.463790</td>\n      <td>0.770065</td>\n      <td>-10.147937</td>\n      <td>3.858490</td>\n      <td>-17.105523</td>\n      <td>-10.306441</td>\n      <td>11.203982</td>\n      <td>24.482049</td>\n      <td>2.786993</td>\n      <td>1.824428</td>\n      <td>...</td>\n      <td>1.069280</td>\n      <td>1.637443</td>\n      <td>-0.467356</td>\n      <td>-2.863164</td>\n      <td>-1.713703</td>\n      <td>-3.485192</td>\n      <td>-7.518907</td>\n      <td>-1.735287</td>\n      <td>-0.889591</td>\n      <td>7.868883</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>49.922700</td>\n      <td>7.560325</td>\n      <td>0.877575</td>\n      <td>15.640722</td>\n      <td>-24.899733</td>\n      <td>9.896629</td>\n      <td>-18.725087</td>\n      <td>-8.175912</td>\n      <td>5.921101</td>\n      <td>1.245585</td>\n      <td>...</td>\n      <td>-3.041447</td>\n      <td>-5.247709</td>\n      <td>2.939720</td>\n      <td>3.391208</td>\n      <td>-0.883789</td>\n      <td>-1.504317</td>\n      <td>-2.896758</td>\n      <td>6.306368</td>\n      <td>-0.465965</td>\n      <td>-3.895691</td>\n    </tr>\n  </tbody>\n</table>\n<p>450 rows × 100 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "finalDfs[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           V1        V2        V3        V4        V5        V6        V7  \\\n721 -0.667148 -1.274329 -2.003620 -0.646775 -1.586510 -0.227039 -0.935964   \n600  0.908517 -0.698231 -0.221392  0.128528 -0.043212  0.126972  2.074642   \n673 -0.842222 -0.986280 -0.518430 -0.646775 -0.969191 -0.581049 -0.434196   \n570 -0.141927 -0.698231  0.075646 -1.422079 -1.586510  1.543013  0.067571   \n73  -0.492074 -0.122133  0.669722  0.645397  0.265447  0.834993 -0.935964   \n..        ...       ...       ...       ...       ...       ...       ...   \n581 -0.667148 -0.122133 -0.518430 -0.388341  0.265447  1.543013 -0.935964   \n687 -1.367444 -0.122133 -0.221392 -1.422079 -0.351872 -0.227039  3.579946   \n408 -1.367444  1.318112 -1.112506  0.645397 -0.969191  0.126972 -0.935964   \n249 -0.667148 -1.274329  0.966760 -0.905210  0.574107 -0.581049 -0.685080   \n2    0.733443 -0.122133 -0.221392  0.128528  0.882767 -0.581049  0.067571   \n\n           V8        V9       V10  ...     V9991     V9992     V9993   V9994  \\\n721 -0.264849  0.027828  0.026434  ... -0.384867 -0.358025 -0.397250 -0.3234   \n600 -0.264849  0.502163 -0.327597  ... -0.384867 -0.358025 -0.397250 -0.3234   \n673 -1.557498  0.027828 -1.035659  ... -0.384867 -0.358025 -0.397250 -0.3234   \n570  0.596917  0.027828 -0.681628  ... -0.384867 -0.358025 -0.397250 -0.3234   \n73   0.596917  0.976499 -1.035659  ... -0.384867 -0.358025 -0.397250 -0.3234   \n..        ...       ...       ...  ...       ...       ...       ...     ...   \n581 -0.695732  0.027828 -1.035659  ... -0.384867 -0.358025  1.537411 -0.3234   \n687 -1.126615  0.027828  1.088528  ...  1.442034 -0.358025 -0.397250 -0.3234   \n408  0.166034 -0.920843 -1.035659  ... -0.384867 -0.358025 -0.397250 -0.3234   \n249 -1.557498 -0.446508  0.734497  ... -0.384867 -0.358025 -0.397250 -0.3234   \n2   -0.695732  1.450834  0.734497  ... -0.384867 -0.358025 -0.397250 -0.3234   \n\n        V9995     V9996     V9997     V9998     V9999    V10000  \n721  1.365069  1.597949 -0.430273 -0.390662 -0.462312  1.579153  \n600 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n673  3.124179 -0.450704 -0.430273 -0.390662 -0.462312  1.579153  \n570 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312  1.579153  \n73  -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n..        ...       ...       ...       ...       ...       ...  \n581 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312  1.579153  \n687 -0.394041  1.597949 -0.430273  1.748000 -0.462312  1.579153  \n408 -0.394041 -0.450704 -0.430273 -0.390662 -0.462312 -0.375244  \n249  1.365069  1.597949 -0.430273  1.748000 -0.462312 -0.375244  \n2   -0.394041  1.597949 -0.430273 -0.390662 -0.462312 -0.375244  \n\n[225 rows x 10000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V9991</th>\n      <th>V9992</th>\n      <th>V9993</th>\n      <th>V9994</th>\n      <th>V9995</th>\n      <th>V9996</th>\n      <th>V9997</th>\n      <th>V9998</th>\n      <th>V9999</th>\n      <th>V10000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>721</th>\n      <td>-0.667148</td>\n      <td>-1.274329</td>\n      <td>-2.003620</td>\n      <td>-0.646775</td>\n      <td>-1.586510</td>\n      <td>-0.227039</td>\n      <td>-0.935964</td>\n      <td>-0.264849</td>\n      <td>0.027828</td>\n      <td>0.026434</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>1.365069</td>\n      <td>1.597949</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>1.579153</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>0.908517</td>\n      <td>-0.698231</td>\n      <td>-0.221392</td>\n      <td>0.128528</td>\n      <td>-0.043212</td>\n      <td>0.126972</td>\n      <td>2.074642</td>\n      <td>-0.264849</td>\n      <td>0.502163</td>\n      <td>-0.327597</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>673</th>\n      <td>-0.842222</td>\n      <td>-0.986280</td>\n      <td>-0.518430</td>\n      <td>-0.646775</td>\n      <td>-0.969191</td>\n      <td>-0.581049</td>\n      <td>-0.434196</td>\n      <td>-1.557498</td>\n      <td>0.027828</td>\n      <td>-1.035659</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>3.124179</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>1.579153</td>\n    </tr>\n    <tr>\n      <th>570</th>\n      <td>-0.141927</td>\n      <td>-0.698231</td>\n      <td>0.075646</td>\n      <td>-1.422079</td>\n      <td>-1.586510</td>\n      <td>1.543013</td>\n      <td>0.067571</td>\n      <td>0.596917</td>\n      <td>0.027828</td>\n      <td>-0.681628</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>1.579153</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>-0.492074</td>\n      <td>-0.122133</td>\n      <td>0.669722</td>\n      <td>0.645397</td>\n      <td>0.265447</td>\n      <td>0.834993</td>\n      <td>-0.935964</td>\n      <td>0.596917</td>\n      <td>0.976499</td>\n      <td>-1.035659</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>581</th>\n      <td>-0.667148</td>\n      <td>-0.122133</td>\n      <td>-0.518430</td>\n      <td>-0.388341</td>\n      <td>0.265447</td>\n      <td>1.543013</td>\n      <td>-0.935964</td>\n      <td>-0.695732</td>\n      <td>0.027828</td>\n      <td>-1.035659</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>1.537411</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>1.579153</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>-1.367444</td>\n      <td>-0.122133</td>\n      <td>-0.221392</td>\n      <td>-1.422079</td>\n      <td>-0.351872</td>\n      <td>-0.227039</td>\n      <td>3.579946</td>\n      <td>-1.126615</td>\n      <td>0.027828</td>\n      <td>1.088528</td>\n      <td>...</td>\n      <td>1.442034</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>1.597949</td>\n      <td>-0.430273</td>\n      <td>1.748000</td>\n      <td>-0.462312</td>\n      <td>1.579153</td>\n    </tr>\n    <tr>\n      <th>408</th>\n      <td>-1.367444</td>\n      <td>1.318112</td>\n      <td>-1.112506</td>\n      <td>0.645397</td>\n      <td>-0.969191</td>\n      <td>0.126972</td>\n      <td>-0.935964</td>\n      <td>0.166034</td>\n      <td>-0.920843</td>\n      <td>-1.035659</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>-0.450704</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>-0.667148</td>\n      <td>-1.274329</td>\n      <td>0.966760</td>\n      <td>-0.905210</td>\n      <td>0.574107</td>\n      <td>-0.581049</td>\n      <td>-0.685080</td>\n      <td>-1.557498</td>\n      <td>-0.446508</td>\n      <td>0.734497</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>1.365069</td>\n      <td>1.597949</td>\n      <td>-0.430273</td>\n      <td>1.748000</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.733443</td>\n      <td>-0.122133</td>\n      <td>-0.221392</td>\n      <td>0.128528</td>\n      <td>0.882767</td>\n      <td>-0.581049</td>\n      <td>0.067571</td>\n      <td>-0.695732</td>\n      <td>1.450834</td>\n      <td>0.734497</td>\n      <td>...</td>\n      <td>-0.384867</td>\n      <td>-0.358025</td>\n      <td>-0.397250</td>\n      <td>-0.3234</td>\n      <td>-0.394041</td>\n      <td>1.597949</td>\n      <td>-0.430273</td>\n      <td>-0.390662</td>\n      <td>-0.462312</td>\n      <td>-0.375244</td>\n    </tr>\n  </tbody>\n</table>\n<p>225 rows × 10000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcas_valid = [pca.transform(X_valid.values) for pca in pcas_objs]\n",
    "valid_Dfs = [pd.DataFrame(data=pca, columns=[f\"pc{i}\" for i in range(1,1+pca.shape[1])]) for pca in pcas_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)\nnum features: 10\noob score: 0.3028571428571429\n----------------------------------------\nRandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)\nnum features: 25\noob score: 0.4095238095238095\n----------------------------------------\nRandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)\nnum features: 100\noob score: 0.41904761904761906\n----------------------------------------\nRandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)\nnum features: 200\noob score: 0.36952380952380953\n----------------------------------------\nRandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True)\nnum features: 225\noob score: 0.3504761904761905\n----------------------------------------\n"
    }
   ],
   "source": [
    "for df, rf in zip(finalDfs, RF_PCAs):\n",
    "    print(rf)\n",
    "    print(f\"num features: {df.shape[1]}\")\n",
    "    rf.fit(df, Y_train)\n",
    "    print(f\"oob score: {rf.oob_score_}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of validation samples: 225\naccuracy: 5.78% --> 13\nnumber of validation samples: 225\naccuracy: 1.78% --> 4\nnumber of validation samples: 225\naccuracy: 5.33% --> 12\nnumber of validation samples: 225\naccuracy: 5.33% --> 12\nnumber of validation samples: 225\naccuracy: 5.33% --> 12\n"
    }
   ],
   "source": [
    "for df, rfc in zip(valid_Dfs, RF_PCAs):\n",
    "    Y_pred = rfc.predict(df)\n",
    "    score = accuracy_score(Y_valid, Y_pred)\n",
    "    print(f\"number of validation samples: {df.shape[0]}\")\n",
    "    print(f\"accuracy: {score*100:.2f}% --> {accuracy_score(Y_valid, Y_pred, normalize=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(1,51), error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('Error rate vs k-Value')\n",
    "plt.xlabel('k-Value')\n",
    "plt.ylabel('Error rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors': range(1, 51)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best k-Value is: \", model.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_data = list(zip(list(range(750,1500)), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_table = pd.DataFrame(solution_data, columns=['ID', 'Class'])\n",
    "solution_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('.mlenv': venv)",
   "language": "python",
   "name": "python37664bitmlenvvenvfbd6963c170645c7aa2859813c621333"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}