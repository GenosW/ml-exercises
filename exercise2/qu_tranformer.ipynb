{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RF\"\n",
    "variation = \"reduced\"\n",
    "\n",
    "n_estimators = 100\n",
    "max_features = \"auto\"\n",
    "if isinstance(max_features, int):\n",
    "    print(\"num features per tree: \", max_features*num_features)\n",
    "max_depth = 4\n",
    "min_samples_leaf = 1 # default\n",
    "min_samples_split = 2 #default\n",
    "criterion = \"gini\" # \n",
    "\n",
    "# Let's check out a default first\n",
    "clf_QT = RFC(n_jobs=-1, criterion=criterion , bootstrap=True, oob_score=True, n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, verbose=0,)\n",
    "start = time()\n",
    "clf_QT.fit(X_train_GB_QT, Y_train)\n",
    "traintime = time() - start\n",
    "cm_rf_QT = confusion_matrix(Y_train, Y_pred)\n",
    "Y_probas = cross_val_predict(clf_QT, X_train_GB_QT, Y_train, cv=5, method=\"predict_proba\")\n",
    "\n",
    "Y_scores = Y_probas[:, 1] # score = proba of positive class\n",
    "fpr, tpr, thresholds = roc_curve(Y_train, Y_scores)\n",
    "\n",
    "plot_roc_curve(fpr, tpr, f\"Random Forest_{n_estimators}\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_rf_QT,  [\"B\", \"G\"],\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix (knn)',\n",
    "                          cmap = plt.cm.Blues)\n",
    "metrics_rf_QT = show_metrics(cm_rf_QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "mets = cross_val_metrics(clf_QT, X_train_GB_QT, Y_train, explain=False)\n",
    "evaltime = time() - start\n",
    "\n",
    "#Y_pred = clf.predict(X_train)\n",
    "Y_pred = cross_val_predict(clf_QT, X_train_GB_QT, Y_train, cv=5)\n",
    "cm_rf_N = confusion_matrix(Y_train, Y_pred)\n",
    "show_metrics(cm_rf_QT)\n",
    "plot_confusion_matrix(cm_rf_QT, [\"B\", \"G\"], normalize = True, title = \"Confusion matrix\", cmap = plt.cm.Reds)\n",
    "#plt.savefig(\"CM_RF_110_entropy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RF\"\n",
    "variation = \"reduced\"\n",
    "\n",
    "n_estimators = [80]\n",
    "max_depth = [4]\n",
    "min_samples_split = [2]\n",
    "\n",
    "max_features = [int(0.5*num_feats), num_feats-1]\n",
    "\n",
    "models_rf = []\n",
    "params = {\"n_estimators\": None, \"max_depth\": None, \"max_features\": None, \"min_samples_split\": None}\n",
    "for i,j,k in itertools.product(n_estimators, max_features, max_depth):\n",
    "    print(i,j,k)\n",
    "    params[\"n_estimators\"]= i\n",
    "    params[\"max_features\"] = \"auto\"\n",
    "    params[\"min_samples_split\"] = j\n",
    "    params[\"max_depth\"] = k\n",
    "    models_rf.append(\n",
    "        (   RFC(n_jobs=-1, bootstrap=True, oob_score=True, n_estimators=i, max_features=int(j), max_depth=k, verbose=0),\n",
    "            model_name+\"_\"+variation, \n",
    "            params.copy())\n",
    "    )\n",
    "print(f\"# {len(models_rf)} different combinations\")\n",
    "cms_rf_GB_QT, res_rf_GB_QT = train_models_GB_QT(models_rf, model_name, variation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rf_reduced = models_rf\n",
    "res_rf_GB_QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm_per_model(cms_rf_GB_QT, models_rf_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_B = MLP_Search(alphas,activation,solver,h,maxiter,X_train_GB_QT, X_valid_GB_QT, Y_train, Y_valid)\n",
    "best_params_GB_QT = FindBestScore(results_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_QT = MLPClassifier(hidden_layer_sizes=(best_params_GB_QT[\"h\"]), max_iter=maxiter, alpha=best_params_GB_QT[\"alpha\"],solver=best_params_GB_QT[\"solver\"],activation=best_params_GB_QT[\"mode\"],tol=1e-9,verbose=False)\n",
    "mlp_QT.fit(X_train_GB_QT, Y_train)\n",
    "Y_pred_GB_QT = mlp_QT.predict(X_valid_GB_QT)\n",
    "Statistic(Y_valid,Y_pred_GB_QT,\"MLP GB_QT\")\n",
    "cm_mlp_QT = confusion_matrix(Y_valid, Y_pred_GB_QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_mlp_QT, [\"B\", \"G\"],\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix (MLP)',\n",
    "                          cmap = plt.cm.Blues)\n",
    "metrics_mlp_QT = show_metrics(cm_mlp_QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP\"\n",
    "variation = \"reduced\"\n",
    "\n",
    "models_mlp = []\n",
    "params = {\"h\": None, \"alphas\": None, \"activations\": None}\n",
    "for i,j,k in itertools.product(h, alphas, activation):\n",
    "    print(i,j,k)\n",
    "    params[\"alphas\"]= i\n",
    "    params[\"activation\"] = \"auto\"\n",
    "    params[\"min_samples_split\"] = j\n",
    "    params[\"max_depth\"] = k\n",
    "    models_mlp.append(\n",
    "        (MLPClassifier(hidden_layer_sizes=(i), max_iter=maxiter, alpha=j,solver=\"adam\",activation=k,tol = 1e-9),\n",
    "         model_name+\"_\"+variation, \n",
    "         params.copy())\n",
    "    )\n",
    "print(f\"# {len(models_mlp)} different combinations\")\n",
    "\n",
    "cms_mlp_GB_QT, res_mlp_GB_QT = train_models_GB_QT(models_mlp, model_name, variation, x=X_train_GB_QT, y=Y_train)   \n",
    "models_mlp_reduced = models_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mlp_GB_QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scores = []\n",
    "best_score = 0\n",
    "best_ks = []\n",
    "ks = list(range(1, 10)) + list(range(10, 20, 2)) + list(range(20, 51, 4))\n",
    "for k in ks:\n",
    "    knn_QT = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_QT.fit(X_train_GB_QT, Y_train)\n",
    "    Y_pred = knn_QT.predict(X_train_GB_QT)\n",
    "    score = accuracy_score(Y_train, Y_pred)\n",
    "    scores.append(score)\n",
    "    best_score = max(scores)\n",
    "    if score == best_score:\n",
    "        best_ks.append(k)\n",
    "    score\n",
    "best_score\n",
    "best_ks.pop(0)\n",
    "#best_ks.pop(0)\n",
    "#best_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ks, scores, label=\"scores\")\n",
    "plt.plot(best_ks, [best_score]*len(best_ks), marker=\"o\", color=\"red\",label=\"best\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "knn_QT = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_QT.fit(X_train_GB_QT, Y_train)\n",
    "Y_pred = knn_QT.predict(X_train_GB_QT)\n",
    "score_knn_QT = accuracy_score(Y_train, Y_pred)\n",
    "cm_knn_QT = confusion_matrix(Y_train, Y_pred)\n",
    "cm_knn_QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "print(\"train set\")\n",
    "cross_val_metrics(knn_QT, X_train_GB_QT, Y_train)\n",
    "# On traination set\n",
    "print(\"-\"*30)\n",
    "print(\"traination set\")\n",
    "cross_val_metrics(knn_QT, X_train_GB_QT, Y_train)\n",
    "# B...1 --> 66%\n",
    "# M...0 --> 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_knn_QT,  [\"B\", \"G\"],\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix (knn)',\n",
    "                          cmap = plt.cm.Blues)\n",
    "metrics_knn_QT = show_metrics(cm_knn_QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "ks = list(range(1, 10)) + list(range(10, 20, 2)) + list(range(20, 51, 4))\n",
    "print(ks)\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "metrics = []\n",
    "for weight in weights:\n",
    "    scores = []\n",
    "    mets = []\n",
    "    best_ks = []\n",
    "    best_k = 0\n",
    "    best_score = 0\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "        #knn.fit(X_train, Y_train)\n",
    "        #Y_pred = knn.predict(X_valid)\n",
    "        #score = accuracy_score(Y_valid, Y_pred)\n",
    "        metric = cross_val_metrics(knn, X_train_GB_QT, Y_train, cv=5, show=False)\n",
    "        mets.append(metric)\n",
    "        score = metric[\"accuracy\"]\n",
    "        scores.append(score)\n",
    "        #best_score = max(scores)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score= score\n",
    "        score\n",
    "    metrics.append(mets)\n",
    "    best_score\n",
    "    best_ks\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.suptitle(f\"Accuracy score over k (weights={weight})\")\n",
    "    plt.plot(ks, scores, label=\"accuracy\")\n",
    "    plt.plot(ks, [met[\"f1\"] for met in mets], label=\"f1\")\n",
    "    plt.plot(best_k, best_score, marker=\"o\", color=\"red\", label=\"best\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f\"figures//wine//knn//scores_k_{weight}_reduced\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}