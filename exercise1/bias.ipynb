{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias correction of numerical prediction model temperature forecast Dataset\n",
    "\n",
    "URL: http://archive.ics.uci.edu/ml/machine-learning-databases/00514/\n",
    "\n",
    "## Content\n",
    "\n",
    "1) [Data preprocessing](#dataproc)\n",
    "\n",
    "2) [Model training and evaluation](#train) \n",
    "\n",
    "2.a) [Random Forest](#rf)\n",
    "    \n",
    "2.b) [Linear regression](#linear)\n",
    "\n",
    "2.c) [Lasso Regression](#lasso)\n",
    "\n",
    "2.d) [kNN](#knn)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "# models for random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "# models for linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# models for Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# models for kNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# statistic tools\n",
    "from sklearn import metrics\n",
    "from statistics import stdev\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1) Data preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be good idea to have a function for dataset analysis --> standardized output\n",
    "# Just a prototype/idea for now\n",
    "def analyse_dataset(frame, name='not-given'):\n",
    "    print(f\"Analysis of <{name}>\")\n",
    "    print('-'*40)\n",
    "    print(\"Info:\")\n",
    "    print(frame.info())\n",
    "    print('-'*40)\n",
    "    print(\"Shape:\")\n",
    "    print(frame.shape)\n",
    "    print('-'*40)\n",
    "    print(\"Index:\")\n",
    "    print(frame.index)\n",
    "    print('-'*40)\n",
    "    print(\"Columns:\")\n",
    "    print(frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'Bias_correction_ucl.csv'\n",
    "print(\"Opening: \", dataset_name)\n",
    "df = pd.read_csv(dataset_name,  sep = ',')#, header = 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis\n",
    "print(f\"Analysis of <{dataset_name}>\")\n",
    "print('-'*40)\n",
    "print(\"Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {c: i for i, c in enumerate(df.columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of data columns\n",
    "\n",
    "1. station - used weather station number: 1 to 25 \n",
    "2. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30') \n",
    "3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6 \n",
    "4. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9 \n",
    "5. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5 \n",
    "6. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100 \n",
    "7. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5 \n",
    "8. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6 \n",
    "9. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9 \n",
    "10. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4 \n",
    "11. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97 \n",
    "12. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97 \n",
    "13. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98 \n",
    "14. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97 \n",
    "15. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7 \n",
    "16. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6 \n",
    "17. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8 \n",
    "18. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7 \n",
    "19. lat - Latitude (Â°): 37.456 to 37.645 \n",
    "20. lon - Longitude (Â°): 126.826 to 127.135 \n",
    "21. DEM - Elevation (m): 12.4 to 212.3 \n",
    "22. Slope - Slope (Â°): 0.1 to 5.2 \n",
    "23. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9 \n",
    "24. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9 \n",
    "25. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look on data and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df.tail().transpose())\n",
    "print('#'*40)\n",
    "display('Some more info')\n",
    "print('#'*40)\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "def split_simple(df, n): \n",
    "    '''n... number to split at'''\n",
    "    return df[:n].copy(), df[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_rf = df\n",
    "cols_to_drop = ['station', 'Date', 'Next_Tmax']\n",
    "df_prep_rf = df_prep_rf.drop(cols_to_drop, axis=1)\n",
    "np.where(np.isnan(df_prep_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "np.where(np.isnan(df_prep_rf))\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "df_imputed = imp.fit_transform(df_prep_rf)\n",
    "df_prep_rf = pd.DataFrame(df_imputed, columns=df_prep_rf.columns)\n",
    "np.where(np.isnan(df_prep_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_prep_rf.columns.values)\n",
    "display(df_prep_rf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df_prep_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = df_prep_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lmplot(\"LDAPS_Tmin_lapse\",\"Next_Tmin\",df_prep_rf)\n",
    "\n",
    "sns.lmplot(\"Present_Tmin\",\"Next_Tmin\",df_prep_rf)\n",
    "\n",
    "sns.lmplot(\"LDAPS_RHmin\",\"Next_Tmin\",df_prep_rf)\n",
    "\n",
    "sns.lmplot(\"LDAPS_RHmax\",\"Next_Tmin\",df_prep_rf)\n",
    "\n",
    "sns.lmplot(\"DEM\",\"Next_Tmin\",df_prep_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model training and evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "from prettytable import PrettyTable as PT # pip install PTable\n",
    "def print_RF_featureImportance(rf, X):\n",
    "    table = PT()\n",
    "    table.field_names = ['Feature', 'Score', 'Comment']\n",
    "    for name, score in zip(X.columns.values, rf.feature_importances_):\n",
    "        print(f\"{name}: {score:.5f}\\t\\t... {col_dict[name]}\")\n",
    "        table.add_row([name, round(score, ndigits=4), col_dict[name]])\n",
    "    print(table)\n",
    "\n",
    "def print_GridSearchResult(grid):\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for random forest\n",
    "\n",
    "rnd_state = 42\n",
    "ratio = 0.2 # test/num_samples\n",
    "#####\n",
    "num_instances, _ = df_rf.shape\n",
    "print(f\"From {num_instances} using {num_instances*ratio:.0f} for testing and {num_instances*(1-ratio):.0f} for training. Ratio = {ratio*100:.2f}%\")\n",
    "X, y = (df_rf.drop(['Next_Tmin'], axis=1), df_rf.Next_Tmin)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = ratio, random_state = rnd_state)\n",
    "display(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simple training of RFRegressor\n",
    "before = 0\n",
    "n_cores = 2\n",
    "rf_model = RandomForestRegressor(n_jobs=n_cores)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "pred = rf_model.predict(X_test)\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "\n",
    "print(\"Model performance:\")\n",
    "print(\"RMSE: {}\".format(error))\n",
    "print(\"R^2-score: {}\".format(rf_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_RF_featureImportance(rf_model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_prediction = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)\n",
    "sns.distplot(rf_model_prediction, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-rf_model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 2\n",
    "number_of_trees = 500 # default = 100\n",
    "rf = RandomForestRegressor(n_jobs=n_cores, n_estimators=number_of_trees, bootstrap=True) #, verbose=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Model performance:\")\n",
    "print(\"RMSE: {}\".format(error))\n",
    "print(\"R^2-score: {}\".format(rf_model.score(X_test, y_test)))\n",
    "\n",
    "print(\"Feature importance\")\n",
    "print_RF_featureImportance(rf, X_train)\n",
    "rf_RD = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfRD_prediction = rf_RD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)\n",
    "sns.distplot(rf_model_prediction, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-rfRD_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Hyperparameters via GridSearch\n",
    "\n",
    "\n",
    "## Notes on the RandomForestRegressor from scikit-learn\n",
    "-----\n",
    "The default values for the parameters controlling the size of the trees\n",
    "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
    "unpruned trees which can potentially be very large on some data sets. To\n",
    "reduce memory consumption, the complexity and size of the trees should be\n",
    "controlled by setting those parameter values.\n",
    "\n",
    "## Number of variables/features per tree --> 'max_features'\n",
    "\n",
    "A good starting point is/might be: *the square root of the number of features presented to the tree*. Then, test some values below and above that starting point.\n",
    "\n",
    "## Number of trees in the forest --> 'n_estimators'\n",
    "\n",
    "The more the merrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "num_features = X.shape[1]\n",
    "print(num_features)\n",
    "sqrt_num_features = round(sqrt(num_features), 0)\n",
    "sqrt_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 2\n",
    "# brute forcing\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [10, 30, 100], 'max_features': [i for i in range(3, 7)]\n",
    "    }\n",
    "#,{'bootstrap': [False], 'n_estimators': [3, 30, 100], 'max_features': [3, 4, 5, 6]},\n",
    "]\n",
    "k = 10\n",
    "forest_reg = RandomForestRegressor(n_jobs=n_cores)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, n_jobs=n_cores , cv=k, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_GridSearchResult(grid_search)\n",
    "grid_search.scorer_\n",
    "scores = grid_search.score(X_test, y_test)\n",
    "pred = grid_search.predict(X_test)\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "\n",
    "print(\"Model performance:\")\n",
    "print(\"RMSE: {}\".format(error))\n",
    "print(\"R^2-score: {}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# b) Linear regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin = df_prep_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(normalize=True)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_\n",
    "\n",
    "pred_linreg = linreg.predict(X_test)\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test, pred_linreg))\n",
    "\n",
    "print(\"Model performance:\")\n",
    "print(\"RMSE: {}\".format(error))\n",
    "print(\"R^2-score: {}\".format(linreg.score(X_test, y_test)))\n",
    "\n",
    "sns.distplot(y_test)\n",
    "sns.distplot(pred_linreg, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-pred_linreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# c) Lasso Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(normalize = True)\n",
    "parameters = {'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,2,5,10,20,30,35,40,45,50,55,100]}\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error',cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressor.fit(X_train,y_train)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso_pred = lasso_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)\n",
    "sns.distplot(y_lasso_pred, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-y_lasso_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# d) kNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = df_prep_rf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_train_knn_scaled = scaler.fit_transform(X_train)\n",
    "X_train_knn = pd.DataFrame(X_train_knn_scaled)\n",
    "\n",
    "X_test_knn_scaled = scaler.fit_transform(X_test)\n",
    "X_test_knn = pd.DataFrame(X_test_knn_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_val_knn = [] # to store rmse values for different k\n",
    "for k in range(35):\n",
    "    k = k + 1\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train_knn, y_train)\n",
    "    pred = model.predict(X_test_knn)\n",
    "    error = math.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "    rmse_val_knn.append(error)\n",
    "    print(\"RMSE for k={}: {}\".format(k, error))\n",
    "    print(\"R^2 for k={}: {}\\n\".format(k, model.score(X_test_knn, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(1,36), rmse_val_knn, color='blue', linestyle='dashed', marker='o',\n",
    "        markerfacecolor='red', markersize=5)\n",
    "plt.title('RMSE vs. k-Value')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing kNN-search for optimal k-Value via Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': range(1, 35)}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=100)\n",
    "model.fit(X_train_knn, y_train)\n",
    "print(\"Best k-Value is: \", model.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = KNeighborsRegressor(n_neighbors=model.best_params_['n_neighbors'])\n",
    "model_cv.fit(X_train_knn, y_train)\n",
    "pred_cv = model.predict(X_test_knn)\n",
    "sns.distplot(y_test)\n",
    "sns.distplot(pred_cv, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-pred_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit24de9dcde5da4d9f837ea055140cd15f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}