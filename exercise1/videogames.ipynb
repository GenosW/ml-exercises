{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bit33c63940e34148b0a2446cd4c0d0e9f7",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Regression:\n",
    "## Choose 4 different methods of regression \n",
    "### a) linear regression\n",
    "### b) polinominal regression"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be good idea to have a function for dataset analysis --> standardized output\n",
    "# Just a prototype/idea for now\n",
    "def analyse_dataset(frame, name='not-given'):\n",
    "    print(f\"Analysis of <{name}>\")\n",
    "    print('-'*40)\n",
    "    print(\"Info:\")\n",
    "    print(frame.info())\n",
    "    print('-'*40)\n",
    "    print(\"Shape:\")\n",
    "    print(frame.shape)\n",
    "    print('-'*40)\n",
    "    print(\"Index:\")\n",
    "    print(frame.index)\n",
    "    print('-'*40)\n",
    "    print(\"Columns:\")\n",
    "    print(frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Video_Games_Sales_as_at_22_Dec_2016'\n",
    "input_file = os.path.split(sys.path[0])[0] + '\\\\datasets\\\\'+dataset_name+'.csv'\n",
    "print(\"Opening: \", input_file)\n",
    "data = pd.read_csv(input_file,  sep = ',')#, header = 0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis\n",
    "print(f\"Analysis of <{dataset_name}>\")\n",
    "print('-'*40)\n",
    "print(\"Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"Columns:\")\n",
    "print(data.columns)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING ###\n",
    "\n",
    "# Drop some columns for now\n",
    "cols_to_drop = ['Publisher', 'Genre', 'Critic_Count', 'Platform', 'Year_of_Release', 'NA_Sales',\n",
    "       'EU_Sales', 'JP_Sales', 'Other_Sales','User_Count', 'Developer', 'Rating', 'Name']\n",
    "prep = data.drop(cols_to_drop, axis = 1)\n",
    "\n",
    "# Fix missing values\n",
    "# There are some 'tbd' values in the scores --> functionally equivalent to NaN so replace to NaN\n",
    "prep = prep.replace('tbd', None)\n",
    "# drop row containing < thresh number of observations = not NaN\n",
    "# --> we only want rows with at least one valid entry in either User_Score or Critic_Score\n",
    "prep = prep.dropna(subset= ['Critic_Score', 'User_Score'], thresh=1)\n",
    "prep = prep.dropna(subset=['Global_Sales'], how='any')\n",
    "print(prep)\n",
    "\n",
    "# Scale User_Score to 0...100 (similiar to Critic_Score)\n",
    "prep['User_Score'] = prep['User_Score'].astype('float').multiply(10)\n",
    "\n",
    "# How to treat the remaining missing values in on of the Scores? \n",
    "# Replace with other if present +- a random value with sigma\n",
    "sigma = 5\n",
    "mod = uniform(-sigma,sigma)\n",
    "prep.User_Score.where((~prep.User_Score.isnull()), round(prep.Critic_Score+mod, 2), inplace=True)\n",
    "prep.Critic_Score.where((~prep.Critic_Score.isnull()), round(prep.User_Score+mod, 2), inplace=True)\n",
    "\n",
    "# Remove outliers in sales\n",
    "from scipy import stats\n",
    "prep = prep[(np.abs(prep.Global_Sales) > 1)]\n",
    "prep = prep[(np.abs(stats.zscore(prep)) < 3).all(axis=1)]\n",
    "\n",
    "### OUTPUT FINAL DATAFRAME ###\n",
    "print('#'*60)\n",
    "print(\"Preprocessing output\")\n",
    "print('#'*60)\n",
    "print(prep)\n",
    "print(prep.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(prep.User_Score, prep.Global_Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\"User_Score\",\"Global_Sales\",prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}