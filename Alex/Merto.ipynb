{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metro Dataset\n",
    "\n",
    "URL: http://archive.ics.uci.edu/ml/machine-learning-databases/00477/\n",
    "\n",
    "## Content\n",
    "\n",
    "1) [Data preprocessing](#dataproc)\n",
    "\n",
    "2) [Model training](#train)\n",
    "    \n",
    "2.a) [Linear regression](#linear)\n",
    "\n",
    "2.b) [Lasso Regression](#lasso)\n",
    "\n",
    "2.c) [Random Forest](#rf)\n",
    "\n",
    "2.d) [kNN](#knn)\n",
    "\n",
    "3) Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models for linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# models for Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# statistic tools\n",
    "from sklearn import metrics\n",
    "from statistics import stdev\n",
    "\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# models for kNN\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataproc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Metro.csv'\n",
    "df_raw = pd.read_csv(input_file,  sep = ',', header = 0)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of data columns\n",
    "\n",
    "holiday ... Columbus Day, Veterans Day, Columbus Day, Veterans Day, Labor Day\n",
    "\n",
    "temp ... Temperature[K]\n",
    "\n",
    "rain_1h ... Amount in mm of rain that occurred in the hour\n",
    "\n",
    "snow_1h ... Amount in mm of snow that occurred in the hour\n",
    "\n",
    "clouds_all ... Numeric Percentage of cloud cover\n",
    "\n",
    "weather_main ... text description of the current weather situation (Clouds, Clear, Rain, Drizzle, Mist, Fog, Thunderstorm, Snow, Haze)\n",
    "\n",
    "weather_description ... text exacter description of the current weather situation\n",
    "\n",
    "date_time ... DateTime Hour of the data collected in local CST time\n",
    "\n",
    "traffic_volume ... Numeric Hourly I-94 ATR 301 reported westbound traffic volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {'holiday':  'holiday', \n",
    "            'temp':  'Temperature',\n",
    "            'rain_1h':  'mm rain in one hour',\n",
    "            'snow_1h':  'mm snow in one hour',\n",
    "            'clouds_all':  'Percentage of clouds',\n",
    "            'weather_main':  'current weather situation',\n",
    "            'weather_description':  'exacter current weather situation',\n",
    "            'date_time': 'date time',\n",
    "            'traffic_volume': 'traffic volume',\n",
    "            'koff':'koff',\n",
    "            'year': 'year',\n",
    "            'mounth': 'mounth',\n",
    "            'day': 'day',\n",
    "            'hour': 'hour'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            display(df)\n",
    "            \n",
    "def add_RD(df):\n",
    "    df['RD'] = df.apply(lambda row: row.RS - row.RA, axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look on DATA and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.tail().transpose())\n",
    "print('#'*40)\n",
    "display('Some more info')\n",
    "print('#'*40)\n",
    "display(df_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornvert the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date colloum in to 4 different coloums and delite the previous coloum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"date_time\"] = pd.to_datetime(df_raw.date_time)\n",
    "df_raw['year'] = df_raw.date_time.dt.year\n",
    "df_raw['mounth'] = df_raw.date_time.dt.month\n",
    "df_raw['day'] = df_raw.date_time.dt.day\n",
    "df_raw['hour'] = df_raw.date_time.dt.hour\n",
    "df_raw = df_raw.drop(\"date_time\", axis = 1)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converts finally the other coloums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cond = []\n",
    "weather_dis = []\n",
    "weather_cond = df_raw.weather_main.unique() #stors the different attributes form the weather_main coloum\n",
    "weather_dis = df_raw.weather_description.unique() #stors the different attributes from the weather_description coloum\n",
    "\n",
    "for i in range(len(weather_cond)):\n",
    "    df_raw.weather_main[df_raw.weather_main == weather_cond[i]] = i #set the different atributes to 0 to 7\n",
    "\n",
    "for i in range(len(weather_dis)):\n",
    "    df_raw.weather_description[df_raw.weather_description == weather_dis[i]] = i #set the different atributes to 0 to 14\n",
    "df_raw.holiday[df_raw.holiday == \"None\"] = 0 \n",
    "df_raw.holiday[df_raw.holiday != 0] = 1\n",
    "df_raw.temp[df_raw.temp < 100] = np.mean(df_raw.temp)\n",
    "df_raw.rain_1h[df_raw.rain_1h > 100] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the koff coloum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could include now another coloum \"koff\" which combines the three coloums \"clouds_all\",\"weather_main\" and \"weather_description\". To do that we have to sclae the values from thees coloums to even all weighst of thees values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_koff = df_raw\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_raw_koff[[\"clouds_all\", \"weather_main\",\"weather_description\"]] = scaler.fit_transform(df_raw_koff[[\"clouds_all\", \"weather_main\",\"weather_description\"]])\n",
    "df_raw_koff[\"koff\"] = df_raw_koff.clouds_all + df_raw_koff.weather_main + df_raw_koff.weather_description\n",
    "\n",
    "df_raw[['holiday','temp','rain_1h','snow_1h','traffic_volume']] = df_raw[['holiday','temp','rain_1h','snow_1h','traffic_volume']].astype(float)\n",
    "df_raw = df_raw_koff.drop(\"koff\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw\n",
    "#df_raw_koff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the raw dataset into the rushhour  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nother way to try to predict the dataset we could concentrate our regression only at the \"rushhour\" which is every das from 8 to 10 am and 15 to 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushour = [8,9,10,15,16,17]\n",
    "#[for i in rushour == 1] \n",
    "#for j in rushour:\n",
    "#df_raw_rush =  df_raw[df_raw.hour == [for i in rushour]]\n",
    "#df_raw_rush = df_raw\n",
    "\n",
    "df_raw_rush =  df_raw[df_raw.hour == 9]\n",
    "df_raw_rush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "def split_simple(df, n): \n",
    "    '''n... number to split at'''\n",
    "    return df[:n].copy(), df[n:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping:\n",
    "\n",
    "Bootstrapping: Selecting data from a data to generate a new dataset of the same size by picking WITH replacement.\n",
    "\n",
    "Example:\n",
    "\n",
    "    > DS = [1,2,3,4]\n",
    "    > could turn into \n",
    "    > DS_bootstrapped = [3,2,4,4]\n",
    "    \n",
    "Consequences:\n",
    "\n",
    "- Instances (rows) of the original set can end up duplicated (multiple times) in the resulting dataset.\n",
    "- Some instances are left out entirely (up to 1/3) --> \"Out-Of-Bag Dataset\" (=OOB Dataset)\n",
    "\n",
    "## Using the OOB Dataset\n",
    "\n",
    "The OOB dataset was not used to construct the tree, so we can actually use it to test our tree and gain some insight into the error measure of the tree.\n",
    "This error is called the \"Out-Of-Bag Error\" (OOB error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three different kinds of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) df_raw which is the raw data without preprocessing\n",
    "\n",
    "2) df_raw_rush which contains only the time where the rushour is\n",
    "\n",
    "3) df_raw_koff which we add a nother coloum wich all koefficients are combinet from the waether discription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_koff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing LinReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Linear regression we are interestet in coloums where are lineary dependet to each other. Our target is now \"traffic_volume\" and we try now to find coloums which have a linear behavior to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw_koff\n",
    "sns_plot = sns.lmplot(\"temp\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "sns_plot.savefig(\"analysis/temp vs traffic_volume_koff.png\")\n",
    "\n",
    "sns_plot = sns.lmplot(\"rain_1h\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "sns_plot.savefig(\"analysis/rain_1h vs traffic_volume_koff.png\")\n",
    "\n",
    "sns_plot = sns.lmplot(\"snow_1h\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "sns_plot.savefig(\"analysis/snow_1h vs traffic_volume_koff.png\")\n",
    "\n",
    "#sns_plot = sns.lmplot(\"clouds_all\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "#sns_plot.savefig(\"analysis/clouds_all vs traffic_volume_koff.png\")\n",
    "\n",
    "#sns_plot = sns.lmplot(\"weather_main\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "#sns_plot.savefig(\"analysis/weather_main vs traffic_volume_koff.png\")\n",
    "\n",
    "#sns_plot = sns.lmplot(\"weather_description\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "#sns_plot.savefig(\"analysis/weather_description vs traffic_volume_koff.png\")\n",
    "\n",
    "sns_plot = sns.lmplot(\"koff\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "sns_plot.savefig(\"analysis/temp vs traffic_volume_koff.png\")\n",
    "\n",
    "#drop_col = [\"holiday\",\"clouds_all\",\"weather_main\",\"year\",\"day\",\"hour\",\"mounth\"]\n",
    "#df_lin = df_raw.drop(drop_col, axis=1)\n",
    "#df_knn = df_lin\n",
    "\n",
    "#fig = sns_hist.get_figure()\n",
    "#fig.savefig(\"output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_rush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing LassoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_lasso = df_raw\n",
    "df_raw_lasso[['holiday','temp','rain_1h','snow_1h','traffic_volume']] = scaler.fit_transform(df_raw[['holiday','temp','rain_1h','snow_1h','traffic_volume']])\n",
    "df_raw_lasso\n",
    "\n",
    "df_raw_rush_lasso = df_raw_rush\n",
    "df_raw_rush_lasso[['holiday','temp','rain_1h','snow_1h','traffic_volume']] = scaler.fit_transform(df_raw_rush[['holiday','temp','rain_1h','snow_1h','traffic_volume']])\n",
    "df_raw_rush_lasso\n",
    "\n",
    "df_raw_koff_lasso = df_raw_koff\n",
    "df_raw_koff_lasso[['holiday','temp','rain_1h','snow_1h','traffic_volume']] = scaler.fit_transform(df_raw_koff[['holiday','temp','rain_1h','snow_1h','traffic_volume']])\n",
    "df_raw_koff_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linear'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression explenasion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a type of regression analysis where the variables have a linear relationship between each other. The goal is to find a minimazed cost function such that:\n",
    "\n",
    "$J = \\frac{1}{n}\\sum_{i = 0}(y_i-\\hat{y}_i)^2$ is minimazed\n",
    "\n",
    "and to calculate the two coefficients form the equation $y = a_0 + a_1 y$\n",
    "\n",
    "To do that the gradient disent method is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #\tholiday \ttemp \train_1h \tsnow_1h \tclouds_all \tweather_main \tweather_description \ttraffic_volume \tyear \tmounth \tday \thour \tkoff\n",
    "Y = df_raw.traffic_volume\n",
    "X = df_raw[['holiday','snow_1h','temp','rain_1h','clouds_all','weather_main','weather_description','year','mounth','hour']]\n",
    "#X = df_raw[['rain_1h','weather_main']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(normalize = True)\n",
    "linreg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_\n",
    "score = linreg.score(X_test,Y_test)\n",
    "print(\"score: \",score)\n",
    "Y_lin_pred = linreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lasso'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lasso regression we have to minimaze the following equation:\n",
    "\n",
    "$J = \\frac{1}{n}\\sum_{i = 1}^M(y_i-\\hat{y}_i)^2 = \\sum_{i = 1}^M\\bigg(y_i-\\sum_{j = 0}^p \\omega_j \\times x_{ij}\\bigg)^2+\\alpha \\sum_{j = 0}^p|\\omega_j|$\n",
    "\n",
    "where $\\alpha$ is the factor from the additional term from the linear regression. The algorythmus below chooses from the list of parameters the best and plug it in the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_raw_lasso.traffic_volume\n",
    "X = df_raw_lasso[['holiday','snow_1h','temp','rain_1h','clouds_all','weather_main','weather_description','year','mounth','hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = df_raw_lasso.traffic_volume\n",
    "#X = df_raw_lasso[['temp','rain_1h','koff']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(normalize = True)\n",
    "parameters = {'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,2,5,10,20,30,35,40,45,50,55,100]}\n",
    "lasso_regressor = GridSearchCV(lasso,parameters,scoring = 'neg_mean_squared_error',cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressor.fit(X_train,Y_train)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lasso_pred = lasso_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_knn = df_prep_rf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_train_knn_scaled = scaler.fit_transform(X_train)\n",
    "X_train_knn = pd.DataFrame(X_train_knn_scaled)\n",
    "\n",
    "X_test_knn_scaled = scaler.fit_transform(X_test)\n",
    "X_test_knn = pd.DataFrame(X_test_knn_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_val_knn = [] # to store rmse values for different k\n",
    "for k in range(36):\n",
    "    k = k + 1\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train_knn, Y_train)\n",
    "    pred = model.predict(X_test_knn)\n",
    "    error = np.sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    rmse_val_knn.append(error)\n",
    "    print(\"RMSE for k={}: {}\".format(k, error))\n",
    "    print(\"R^2 for k={}: {}\\n\".format(k, model.score(X_test_knn, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(range(1,37), rmse_val_knn, color='blue', linestyle='dashed', marker='o',\n",
    "        markerfacecolor='red', markersize=5)\n",
    "plt.title('RMSE vs. k-Value')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('RMSE')\n",
    "plt.savefig('analysis/RMSE vs k-Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def rmse(x,y): \n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m, X_train, X_valid, y_train, y_valid, score=''):\n",
    "    res = {\n",
    "        'RMS(train)': rmse(m.predict(X_train), y_train),\n",
    "        'RMS(valid)': rmse(m.predict(X_valid), y_valid)}\n",
    "    if score=='neg_mean_squared_error':\n",
    "        res['Model_Score=r²'] = [np.sqrt(-m.score(X_train, y_train)), np.sqrt(-m.score(X_valid, y_valid))]\n",
    "    elif score=='pos_mean_squared_error':\n",
    "        res['Model_Score=r²'] = [np.sqrt(m.score(X_train, y_train)), np.sqrt(m.score(X_valid, y_valid))]\n",
    "    else:\n",
    "        res['Model_Score=r²'] = [m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res['oob_score_'] = m.oob_score_\n",
    "    display(res)\n",
    "    return res\n",
    "\n",
    "# Feature importance\n",
    "from prettytable import PrettyTable as PT # pip install PTable\n",
    "def print_RF_featureImportance(rf, X):\n",
    "    table = PT()\n",
    "    table.field_names = ['Feature', 'Score', 'Comment']\n",
    "    for name, score in zip(X.columns.values, rf.feature_importances_):\n",
    "        print(f\"{name}: {score:.5f}\\t\\t... {col_dict[name]}\")\n",
    "        table.add_row([name, round(score, ndigits=4), col_dict[name]])\n",
    "    print(table)\n",
    "\n",
    "def print_GridSearchResult(grid):\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for random forest\n",
    "df = df_raw\n",
    "rnd_state = 42\n",
    "ratio = 0.2 # test/num_samples\n",
    "#####\n",
    "num_instances, _ = df.shape\n",
    "print(f\"From {num_instances} using {num_instances*ratio:.0f} for testing and {num_instances*(1-ratio):.0f} for training. Ratio = {ratio*100:.2f}%\")\n",
    "#X, y = (d.drop(['W', 'RD'], axis=1), df.W)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = ratio, random_state = rnd_state)\n",
    "display(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training of RFRegressor\n",
    "n_cores = 4\n",
    "rf_W = RandomForestRegressor(n_jobs=n_cores)\n",
    "# The following code is supposed to fail due to string values in the input data\n",
    "rf_W.fit(X_train, Y_train)\n",
    "print(\"Before:\")\n",
    "display(before)#\n",
    "print(\"Now:\")\n",
    "before = print_score(rf_W, X_train, X_test, Y_train, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_RF_featureImportance(rf_W, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_W_prediction = rf_W.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 4\n",
    "number_of_trees = 100 # default = 100\n",
    "rf = RandomForestRegressor(n_jobs=n_cores, n_estimators=number_of_trees, bootstrap=True) #, verbose=1)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"Before:\")\n",
    "display(before)#\n",
    "print(\"Now:\")\n",
    "before = print_score(rf, X_train, X_test, Y_train, Y_test)\n",
    "print()\n",
    "print(\"Feature importance\")\n",
    "print_RF_featureImportance(rf, X_train)\n",
    "rf_RD = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfRD_prediction = rf_RD.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Hyperparameters via GridSearch\n",
    "\n",
    "because we lazy bois\n",
    "\n",
    "## Notes on the RandomForestRegressor from scikit-learn\n",
    "-----\n",
    "The default values for the parameters controlling the size of the trees\n",
    "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
    "unpruned trees which can potentially be very large on some data sets. To\n",
    "reduce memory consumption, the complexity and size of the trees should be\n",
    "controlled by setting those parameter values.\n",
    "\n",
    "## Number of variables/features per tree --> 'max_features'\n",
    "\n",
    "A good starting point is/might be: *the square root of the number of features presented to the tree*. Then, test some values below and above that starting point.\n",
    "\n",
    "## Number of trees in the forest --> 'n_estimators'\n",
    "\n",
    "The more the merrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "num_features = X.shape[1]\n",
    "print(num_features)\n",
    "sqrt_num_features = round(sqrt(num_features), 0)\n",
    "sqrt_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "n_cores = 4\n",
    "# but since we dont have that many features...we are just gonna brute force it :D\n",
    "#[3, 10, 30, 100, 1000]\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [3, 10, 20,30], 'max_features': [i for i in range(1,num_features+1)]\n",
    "    }\n",
    "#,{'bootstrap': [False], 'n_estimators': [3, 30, 100, 1000], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "k = 10\n",
    "forest_reg = RandomForestRegressor(n_jobs=n_cores)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, n_jobs=n_cores , cv=k, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_GridSearchResult(grid_search)\n",
    "grid_search.scorer_()\n",
    "scores = grid_search.score(X_test, Y_test)\n",
    "print_score(grid_search, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Run', 'Score']\n",
    "    for i, score in enumerate(scores):\n",
    "        table.add_row([i, round(score, 3)])\n",
    "    print(table)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "model = rf_RD\n",
    "scores = cross_val_score(model, X, Y, scoring=\"neg_mean_squared_error\", cv=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_train, Y_lin_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_train, Y_lin_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_train, Y_lin_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(Y_train - Y_lin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns_plot = sns.lmplot(\"snow_1h\",\"traffic_volume\",df_raw).set(title = 'temp vs traffic_volume_koff')\n",
    "#sns_plot.savefig(\"analysis/snow_1h vs traffic_volume_koff.png\")\n",
    "\n",
    "sns_plot = sns.distplot(Y_train).set(title = 'linear regression vs train_data')\n",
    "sns_plot = sns.distplot(Y_lin_pred)\n",
    "#sns_plot.savefig(\"analysis/linear prediction vs train_data.png\")\n",
    "\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"analysis/linear regression vs train_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(Y_train - Y_lasso_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.distplot(Y_train).set(title = 'lasso regression vs train_data')\n",
    "sns_plot = sns.distplot(Y_lasso_pred)\n",
    "\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"analysis/lasso regression vs train_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.distplot(Y_test-rfRD_prediction)\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"analysis/different between Test_data and prediction_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.distplot(rfRD_prediction)\n",
    "sns_plot = sns.distplot(Y_test)\n",
    "\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"analysis/different between Test_data and prediction_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geht leider noch nicht die dimesionen passen nicht zusammen\n",
    "#print('Mean Absolute Error:', metrics.mean_absolute_error(Y_train, Y_lasso_pred))  \n",
    "#print('Mean Squared Error:', metrics.mean_squared_error(Y_train, Y_lasso_pred))  \n",
    "#print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_train, Y_lasso_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "joblib.dump(rf_RD, \"tmp/rf_RD.pkl\")\n",
    "# To load the model\n",
    "# my_model_loaded = joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_raw.to_feather('tmp/bulldozers-raw')\n",
    "df_raw = pd.read_feather('tmp/raw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitb5f188b5fd4549769c9ea1e1a366fa0d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
